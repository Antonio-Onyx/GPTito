{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "#text = \"El perro persigue al gato y se lo come\"\n",
    "#text.split()\n",
    "\n",
    "vocab = [\"<pad>\", 'El', 'perro', 'persigue', 'al', 'gato', 'y', 'se', 'lo', 'come', \"<end>\"]\n",
    "\n",
    "def text_to_tokens(text, vocab):\n",
    "    tokens = text.split(\" \")\n",
    "    return [vocab.index(token) if token in vocab else vocab.index(\"<pad>\") for token in tokens]\n",
    "\n",
    "frase = \"El perro persigue al gato\"\n",
    "tokens = text_to_tokens(frase, vocab)\n",
    "print(f\"Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformer import *\n",
    "import torch\n",
    "from transformer import TransformerEncoder, TransformerDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covertimos a un tensor los tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "d_model = 512\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "max_seq_length = 5 # este tiene que tener el mismo tama√±o de los tokens (checar tokens.shape[1] si es de una dimension, tokens.shape[1] si son dos dimensiones)\n",
    "batch_size = 1\n",
    "\n",
    "src_mask = torch.ones(batch_size, 1, max_seq_length, max_seq_length) # mascara que es una amtriz de solos 1s porque no tenemos tokens con padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "output_encoder = encoder(tokens, src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_encoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8489, -1.1280, -0.2287,  ...,  0.1213, -0.1577,  0.2173],\n",
       "         [-1.2415, -0.3410, -0.3437,  ..., -0.3859, -1.1471,  0.5902],\n",
       "         [-1.1081, -0.6612,  1.2506,  ...,  0.4980,  1.9909,  0.3542],\n",
       "         [-2.0391,  0.4942, -0.2122,  ...,  0.4761,  0.7242, -0.1719],\n",
       "         [-0.1632, -0.6623,  0.6064,  ...,  0.8727,  0.8184,  0.6456]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_encoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

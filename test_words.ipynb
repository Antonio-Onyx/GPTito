{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "vocab = [\"<pad>\", 'El', 'perro', 'persigue', 'al', 'gato', 'y', 'se', 'lo', 'come', \"<end>\"]\n",
    "\n",
    "def text_to_tokens(text, vocab):\n",
    "    tokens = text.split(\" \")\n",
    "    return [vocab.index(token) if token in vocab else vocab.index(\"<pad>\") for token in tokens]\n",
    "\n",
    "frase = \"El perro persigue al gato\"\n",
    "tokens = text_to_tokens(frase, vocab)\n",
    "print(f\"Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformer import *\n",
    "import torch\n",
    "from Transformer import TransformerEncoder, TransformerDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covertimos a un tensor los tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "d_model = 512\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "max_seq_length = 5 # este tiene que tener el mismo tama√±o de los tokens (checar tokens.shape[1] si es de una dimension, tokens.shape[1] si son dos dimensiones)\n",
    "batch_size = 1\n",
    "\n",
    "src_mask = torch.ones(batch_size, 1, max_seq_length, max_seq_length) # mascara que es una matriz de solos 1s porque no tenemos tokens con padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "output_encoder = encoder(tokens, src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_encoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3027, -0.4166, -0.3483,  ...,  0.2584,  0.7550,  0.5118],\n",
       "         [ 2.6200,  0.5712,  0.2206,  ...,  0.3799,  1.2838,  0.5919],\n",
       "         [ 1.0583, -0.8786,  0.1824,  ...,  0.9739, -0.7818,  0.4144],\n",
       "         [ 0.1919,  0.7549,  0.6356,  ...,  1.3993, -0.3338, -0.1261],\n",
       "         [-0.9554,  0.3679,  0.7908,  ...,  0.9905,  0.7334,  0.7674]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf],\n",
      "        [0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0.]])\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "tgt = torch.triu(torch.ones(4, 4) * float('-inf'), diagonal=1)\n",
    "print(tgt)\n",
    "print(tgt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "x = tokens[:, :-1]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = TransformerDecoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "output_decoder = decoder(x, output_encoder, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wow, looks just we must fix something here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

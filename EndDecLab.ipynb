{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "d_model = 512\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "max_seq_length = 10\n",
    "batch_size = 2\n",
    "\n",
    "tokens = torch.randint(0, vocab_size, (batch_size, max_seq_length))\n",
    "src_mask = torch.ones(batch_size, 1, max_seq_length, max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_encoder = TranformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = transformer_encoder(tokens, src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ClassifierHead(d_model, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 5])\n",
      "Logits: tensor([[-1.9659, -2.1014, -1.3732, -1.4973, -1.3445],\n",
      "        [-2.3736, -1.6140, -1.0863, -1.8565, -1.5414]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cls_respresentattion = output[:, 0, :]\n",
    "logits = classifier(cls_respresentattion)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(\"Logits:\", logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression output shape: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "regressor = RegressionHead(d_model, output_dim=1)\n",
    "regression_output = regressor(cls_respresentattion)\n",
    "print(\"Regression output shape:\", regression_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5168],\n",
       "        [-0.2422]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tgt_mask(seq_len):\n",
    "    return torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "tgt_seq_len = max_seq_length\n",
    "tgt = torch.rand(batch_size, tgt_seq_len, d_model)\n",
    "tgt_mask = generate_tgt_mask(tgt_seq_len)\n",
    "\n",
    "decoder_layer = DecoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "output_decoder_layer = decoder_layer(tgt, output, tgt_mask)\n",
    "print(\"Decoder output shape:\", output_decoder_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4046, -1.8119, -0.1540,  ..., -1.4842,  0.5221, -1.7169],\n",
       "         [-2.3092, -2.1600,  1.4733,  ...,  0.7517,  0.7313, -1.3751],\n",
       "         [ 0.5899,  0.4951,  0.8977,  ..., -0.8767, -0.1960, -0.3707],\n",
       "         ...,\n",
       "         [-0.8261, -0.5276, -0.2341,  ..., -0.3555, -0.9859, -0.6180],\n",
       "         [-0.2501, -0.1086,  1.3521,  ..., -0.3142, -0.7225, -0.9077],\n",
       "         [-0.1234, -0.0985,  1.5096,  ...,  0.7190, -1.6096,  1.1190]],\n",
       "\n",
       "        [[-2.0849, -0.6344,  1.2268,  ...,  0.5142,  0.0996,  1.2028],\n",
       "         [-2.0038, -2.5707,  2.0834,  ...,  1.1457, -2.0182, -0.3672],\n",
       "         [-1.4734, -1.6599,  0.5760,  ...,  0.8894, -1.4828,  1.0271],\n",
       "         ...,\n",
       "         [ 0.2398, -0.4471,  0.7239,  ..., -0.4634,  0.3087, -1.0807],\n",
       "         [-1.6472, -1.6188,  0.7646,  ...,  0.9864,  0.4554, -0.2269],\n",
       "         [ 0.6739, -0.6478,  0.0313,  ..., -1.1234, -1.3882, -1.3978]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_decoder_layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
